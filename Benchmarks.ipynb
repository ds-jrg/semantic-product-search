{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0c5014-3ebd-4ddd-af7f-49d2f2100321",
   "metadata": {},
   "source": [
    "# Semantic Product Search Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4db4f6-bc00-44ca-bdb9-47833ed5eff3",
   "metadata": {},
   "source": [
    "In the jupyterconsole download the following packages:\n",
    "pip install datasets, accelerate, transformers[torch], rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241d72f8-5cb3-4726-834d-0a484f071919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import tqdm\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.nn import GCNConv, FastRGCNConv, RGCNConv, RGATConv\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers import evaluation\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
    "\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "import re\n",
    "from sentence_transformers import CrossEncoder, InputExample, losses, models\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import traceback\n",
    "from torch.nn import MSELoss\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainer, CrossEncoderTrainingArguments\n",
    "#from datasets import Dataset, Features, Value\n",
    "from sentence_transformers.cross_encoder import (\n",
    "    CrossEncoder,\n",
    "    CrossEncoderModelCardData,\n",
    "    CrossEncoderTrainer,\n",
    "    CrossEncoderTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderNanoBEIREvaluator\n",
    "from sentence_transformers.cross_encoder.losses import CachedMultipleNegativesRankingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f61e684-9967-4ea7-b4ad-99c0dfc97dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentence_transformer_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec41ea6-1c21-4f0b-b04b-2689cda38500",
   "metadata": {},
   "source": [
    "## Select Subset, Trainingversio and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c6fb4b-e3c2-4539-a82d-0ce921cf43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amazon = \"wands\"\n",
    "amazon = \"amazon\"\n",
    "\n",
    "training_version = \"shuffle\"\n",
    "#training_version = \"predict\"\n",
    "\n",
    "test_subset = 0 # 0...5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d1d93-b540-4d8e-af43-a5d381addbf7",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed94ea5-9bac-41bf-a702-a338aab74b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if amazon == \"amazon\":\n",
    "    df_examples = pd.read_parquet('data/esci-data/shopping_queries_dataset_examples.parquet')\n",
    "    df_products = pd.read_parquet('data/esci-data/shopping_queries_dataset_products.parquet')\n",
    "    \n",
    "    df_examples = df_examples[df_examples[\"product_locale\"] == \"us\"]\n",
    "    df_products = df_products[df_products[\"product_locale\"] == \"us\"]\n",
    "    \n",
    "    # Reduce to smaller subset\n",
    "    df_examples = df_examples[df_examples[\"small_version\"] == 1]\n",
    "\n",
    "else:\n",
    "    df_products = pd.read_csv(\"data/wands-data/product.csv\", sep='\\t')\n",
    "    query_df = pd.read_csv(\"data/wands-data/query.csv\", sep='\\t')\n",
    "    label_df = pd.read_csv(\"data/wands-data/label.csv\", sep='\\t')\n",
    "    df_examples = label_df\n",
    "\n",
    "# we want to split data early, reduce unnecessary data cleaning,...\n",
    "match test_subset:\n",
    "    case 0:\n",
    "        desired_length = 10000\n",
    "        rkey = 42\n",
    "    case 1:\n",
    "        desired_length = 10000\n",
    "        rkey = 43\n",
    "    case 2:\n",
    "        desired_length = 10000\n",
    "        rkey = 69\n",
    "    case 3:\n",
    "        desired_length = 50000\n",
    "        rkey = 42\n",
    "    case 4:\n",
    "        desired_length = 50000\n",
    "        rkey = 43\n",
    "    case 5:\n",
    "        desired_length = 50000\n",
    "        rkey = 69\n",
    "    case 6:\n",
    "        desired_length = 300000\n",
    "        rkey = 369\n",
    "\n",
    "rng = np.random.default_rng(rkey)\n",
    "    \n",
    "qids = df_examples['query_id'].unique() # all querys\n",
    "num_queries = int(desired_length/(len(df_examples)/ len(qids))) # desired length/ avg depth\n",
    "# for calculating ca. desired length many queries\n",
    "qids_to_use = rng.choice(qids, size=num_queries, replace=False)\n",
    "\n",
    "# include all querys from those qids and only the included products\n",
    "df_examples = df_examples[df_examples[\"query_id\"].isin(qids_to_use)]\n",
    "df_products = df_products[df_products[\"product_id\"].isin(df_examples[\"product_id\"])]\n",
    "\n",
    "## Save the qids in csv, for retraining\n",
    "if not os.path.exists(f\"data/subset-csvs/{amazon,test_subset}.txt\"):\n",
    "    with open(f'data/subset-csvs/{amazon,test_subset}.txt', 'w') as f:\n",
    "        f.write(str(qids_to_use))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5ee7f-c847-42ca-a947-3782cf94ac48",
   "metadata": {},
   "source": [
    "### Creating some helper functions/ functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39cce7db-bece-4b41-9c25-87d5bcb4d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_color(df_products):\n",
    "    colors = [\"WHITE\", \"YELLOW\", \"BLUE\", \"RED\", \"GREEN\", \"BLACK\", \"BROWN\", \"AZURE\", \"IVORY\", \"TEAL\", \"SILVER\", \"PURPLE\", \"NAVY BLUE\", \"PEA GREEN\", \"GRAY\", \"ORANGE\", \"MAROON\", \"CHARCOAL\", \"AQUAMARINE\", \"CORAL\", \"FUCHSIA\", \"WHEAT\", \"LIME\", \"CRIMSON\", \"KHAKI\", \"HOT PINK\", \"MAGENTA\", \"OLDEN\", \"PLUM\", \"OLIVE\", \"CYAN\"]\n",
    "    pattern = '|'.join(colors)\n",
    "    \n",
    "    def process_colors(text):\n",
    "        if text is None: return '[]'\n",
    "        matches = re.findall(pattern, text.upper())\n",
    "        return str(matches) if matches else '[]'\n",
    "    \n",
    "    df_products['product_color'] = df_products['product_color'].apply(process_colors)\n",
    "    return df_products\n",
    "\n",
    "def clean_prod_desc(df_products):\n",
    "    def process_info(text):\n",
    "        if text is None: return text\n",
    "        r = 0\n",
    "        text_c = \"\"\n",
    "        for i in text:\n",
    "            if r == 0 and i != \"<\": text_c += i\n",
    "            elif i == \">\":\n",
    "                r = 0\n",
    "            else: \n",
    "                r = 1\n",
    "        return text_c\n",
    "    df_products['product_description'] = df_products['product_description'].apply(process_info)\n",
    "    return df_products\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def clean_emojis_symbols(text):\n",
    "    return text.astype(str).apply(lambda x: emoji_pattern.sub(\"\", x))\n",
    "\n",
    "def create_label_dict(df, label, label_map):\n",
    "    return {(row['query_id'], row['product_id']): label_map[row[label]] for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cc96a8-beea-4836-a46f-f0848657c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if amazon == 'amazon':\n",
    "    label = 'esci_label'\n",
    "    product_txt = 'product_title'\n",
    "    df_products = clean_prod_desc(df_products)\n",
    "    df_products = clean_color(df_products)\n",
    "    df_products['product_bullet_point'] = clean_emojis_symbols(df_products['product_bullet_point'])\n",
    "    df_products['product_title'] = clean_emojis_symbols(df_products['product_title'])\n",
    "    product_infos = ['product_title', 'product_description', 'product_bullet_point'] \n",
    "else:\n",
    "    label = 'label' \n",
    "    product_txt = 'product_name'\n",
    "    df_products['product_name'] = clean_emojis_symbols(df_products['product_name'])\n",
    "    df_products['product_features'] = clean_emojis_symbols(df_products['product_features'])\n",
    "    df_examples = pd.merge(df_examples, query_df, how='left', on='query_id')\n",
    "    product_infos = ['product_name', 'product_description', 'product_features']\n",
    "\n",
    "# Sorting by query-id, so that train, val, test splits are useful\n",
    "df_examples = df_examples.sort_values(by='query_id')\n",
    "\n",
    "# Assign a unique sequential node ID to each product (for easier accessing) from 0 to len(df_products)\n",
    "df_products = df_products.reset_index(drop=True).copy()\n",
    "df_products['node_id'] = range(len(df_products))\n",
    "# Map between original product indices and node_ids\n",
    "product_id_to_node_id = dict(zip(df_products['product_id'], df_products['node_id']))\n",
    "node_id_to_product_id = dict(zip(df_products['node_id'], df_products['product_id']))\n",
    "\n",
    "# Create a lookup table for product relevancy\n",
    "label_map = {\"E\": 1, \"S\": 0.1, \"C\":0.01, \"I\": 0, \"Exact\":1, \"Partial\":0.2, \"Irrelevant\":0}\n",
    "label_dict = create_label_dict(df_examples, label, label_map)\n",
    "\n",
    "all_product_info = []\n",
    "for _,row in df_products.iterrows():\n",
    "    all_product_info.append(\" \".join(str(row[field]) for field in product_infos if pd.notnull(row[field])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2230a-dd8f-4706-9f88-42f93fa0ff46",
   "metadata": {},
   "source": [
    "## Create Train, Eval, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884d3235-6323-43f1-9aea-73e73101b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(df_examples)\n",
    "train_parts = int(0.7*total_len)\n",
    "eval_parts = int(0.1*total_len)\n",
    "test_parts = total_len - eval_parts - train_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d65ced5-c124-4505-95a0-227abc2f541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_version == 'predict' and amazon == 'amazon': # to predict unseen questions\n",
    "    train_data = df_examples[df_examples['split']== 'train'] \n",
    "    train_data, eval_data = train_data[:int(len(train_data)*.8)],train_data[int(len(train_data)*0.8+1):]\n",
    "    test_data = df_examples[df_examples['split']== 'test'] \n",
    "elif training_version == 'predict':\n",
    "    train_data = df_examples.iloc[:train_parts,:]\n",
    "    eval_data = df_examples.iloc[train_parts:(train_parts+eval_parts),:]\n",
    "    test_data = df_examples.iloc[(train_parts+eval_parts):,:]\n",
    "else:\n",
    "    splits = random_split(\n",
    "        df_examples,\n",
    "        [train_parts, eval_parts, test_parts],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    train_idx, val_idx, test_idx = [list(s.indices) for s in splits]\n",
    "    \n",
    "    train_data = df_examples.iloc[train_idx]\n",
    "    eval_data  = df_examples.iloc[val_idx]\n",
    "    test_data  = df_examples.iloc[test_idx]\n",
    "    \n",
    "old_test_data = test_data.copy()\n",
    "test_data = test_data[['query','query_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f80278-a522-4535-b1a8-47af8807dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe Subset Examples: 9755\n",
      "Größe Subset Products: 9671\n",
      "Amount of queries: 496\n",
      "Größe Subset Training: 6828\n",
      "Größe Eval Training: 975\n",
      "Größe Subset Test: 487\n",
      "AVG DEPTH: 19.66733870967742\n",
      "{'S': 3548, 'I': 1631, 'C': 369, 'E': 4207}\n"
     ]
    }
   ],
   "source": [
    "print(\"Größe Subset Examples:\",len(df_examples))\n",
    "print(\"Größe Subset Products:\",len(df_products))\n",
    "print(\"Amount of queries:\",len(df_examples['query_id'].unique()))\n",
    "print(\"Größe Subset Training:\", len(train_data))\n",
    "print(\"Größe Eval Training:\", len(eval_data))\n",
    "print(\"Größe Subset Test:\", len(test_data))\n",
    "print(\"AVG DEPTH:\",len(df_examples)/len(df_examples['query_id'].unique()))\n",
    "depth = len(df_examples)/len(df_examples['query_id'].unique())\n",
    "counti = {}\n",
    "for value in df_examples[label]:\n",
    "    if value not in counti:\n",
    "        counti[value] = 0\n",
    "    counti[value] += 1\n",
    "print(counti) \n",
    "#with open(f'outputs/subset-specifics.txt', 'a') as f:\n",
    " #   f.write(f'{amazon}{test_subset} :: {len(df_examples)}, {len(df_products)} ,{depth} , {counti} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848207b8-c37b-4cd1-9f68-29af6e596066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDataset(Dataset):\n",
    "    def __init__(self, df, batch_size=64):\n",
    "        self.pairs = []\n",
    "        query_ids = df['query_id'].tolist()          # query, qid, product_id\n",
    "        queries = df['query'].tolist()\n",
    "        \n",
    "        all_embeddings = [query.split(\" \") for query in queries]\n",
    "\n",
    "        for emb, qid in zip(all_embeddings, query_ids):\n",
    "            self.pairs.append((emb, qid))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb, qid = self.pairs[idx]\n",
    "        return emb, qid\n",
    "        \n",
    "def collate_fn(batch):\n",
    "    emb = [item[0] for item in batch]\n",
    "    query_ids = [item[1] for item in batch]\n",
    "    return emb, query_ids\n",
    "\n",
    "dataset = QueryDataset(test_data)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1843587f-d734-4612-8bc9-8a78c3ac191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, dataloader, product_emb):\n",
    "        self._dataloader = dataloader\n",
    "        self._product_embeddings = product_emb # doesnt need to be emb, can also be just strings\n",
    "    \n",
    "        \"\"\" \n",
    "    def forwards(self, query):\n",
    "        # needs to get implemented by every one calling eval\n",
    "        \"\"\"\n",
    "    \n",
    "    def evaluate(self, skip=False):\n",
    "        self.skip = skip\n",
    "        # called self.forward\n",
    "        if self.skip: mrr, ndcg, p_at_k, r_precision, sci_ap = [], [], [], [], 0\n",
    "        else: mrr, ndcg, p_at_k, r_precision, sci_ap= [], [], [], [], []\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for queries, qids in self._dataloader:\n",
    "                for i in range(len(queries)):\n",
    "                    #sim_scores = bm25.get_scores(queries[i])\n",
    "                    sim_scores = self.forwards(queries[i], self._product_embeddings)\n",
    "                    \n",
    "                    # Represents the node-indexes with decreasing similarity\n",
    "                    sim_indx = np.argsort(sim_scores)[::-1].tolist()\n",
    "                   \n",
    "                    \n",
    "                     # Create relevance vector            \n",
    "                    relevance = [0]*len(sim_indx)\n",
    "                    for j in range(len(sim_indx)):\n",
    "                        pid = node_id_to_product_id[sim_indx[j]]\n",
    "                        if type(qids[i]) != int:\n",
    "                            rel = label_dict.get((qids[i].item(),pid), 0)\n",
    "                        else:\n",
    "                            rel = label_dict.get((qids[i],pid), 0)\n",
    "                        if rel < 1: continue\n",
    "                        relevance[j] = 1\n",
    "        \n",
    "                    # Total of positive matches\n",
    "                    total_pos = sum(relevance)\n",
    "                    \n",
    "                    if total_pos == 0: \n",
    "                        continue\n",
    "                        \n",
    "                    relevance = np.array(relevance)\n",
    "        \n",
    "                    # Precision at k= relevant geschnit retrieved / retrieved\n",
    "                    def p_for_k(x): \n",
    "                        return sum(relevance[:x+1]) / (x+1)\n",
    "        \n",
    "                    # Precision at top k\n",
    "                    p_at_k.append(p_for_k(10))\n",
    "        \n",
    "                    # R-Precision: relevant, among sum relevant\n",
    "                    r_precision.append(sum(relevance[:total_pos])/total_pos)\n",
    "              \n",
    "                    # MRR \n",
    "                    ranks = np.where(relevance == 1)[0]\n",
    "                    if len(ranks) > 0:\n",
    "                        mrr.append(1.0 / (ranks[0] + 1))\n",
    "                    else:\n",
    "                        mrr.append(0)\n",
    "        \n",
    "                    # NDCG\n",
    "                    def dcg():\n",
    "                        dcg_im = 0\n",
    "                        for l in ranks.tolist():\n",
    "                            dcg_im += 1 /( np.log2(l + 1 +1)) # bcs we start at 0\n",
    "                        return dcg_im\n",
    "                        \n",
    "                    def idcg(): \n",
    "                        idcg_im = 0\n",
    "                        for n in range(total_pos):\n",
    "                            idcg_im += 1 / (np.log2(n + 1 + 1))\n",
    "                        return idcg_im\n",
    "                    ndcg.append(dcg() / idcg())\n",
    "        \n",
    "                    # MAP with Scikit-learn ony if skip == False\n",
    "                    if not self.skip:\n",
    "                        def maper(x): \n",
    "                            if x == '1': \n",
    "                                return 1 \n",
    "                            else: \n",
    "                                return 0 \n",
    "                        y_true = np.array([maper(str(label_dict.get((qids[i],c), 0)))   for c in df_products['product_id']])\n",
    "                        sci_ap.append(average_precision_score(y_true, sim_scores))\n",
    "                \n",
    "            return {\n",
    "                    \"MRR\": float(np.mean(mrr)),\n",
    "                    \"nDCG\": float(np.mean(ndcg)),\n",
    "                    \"R-Precision\": float(np.mean(r_precision)),\n",
    "                    \"Precision@k\": float(np.mean(p_at_k)),\n",
    "                    \"Scikit-MAP\": float(np.mean(sci_ap))\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c979b3-20ad-484e-923b-ca4f6c725323",
   "metadata": {},
   "source": "## Database with random guesses"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f984b5cc-0911-4394-bc55-f9f6d263b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_to_prod = {}\n",
    "for _,p in train_data.iterrows():\n",
    "    query = str(p['query']).strip().lower()\n",
    "    q = \" \".join(query.split())\n",
    "    if q not in query_to_prod:\n",
    "        query_to_prod[q] = []\n",
    "    if p[label] == \"Exact\" or p[label] == 'E':\n",
    "        query_to_prod[q].append(p['product_id'])\n",
    "\n",
    "for l in query_to_prod:\n",
    "    if query_to_prod[l] is None:\n",
    "        print(\"xd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c44370-3c7f-40b8-9f7f-9657238491fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.9651009326698826, 'nDCG': 0.8231041799566408, 'R-Precision': 0.6888552799937497, 'Precision@k': 0.48665297741273095, 'Scikit-MAP': 0.6885312428138274}\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "class Eval_db(Evaluator):\n",
    "    def forwards(self, query, p_embeddings):\n",
    "        query= \" \".join(i for i in query)\n",
    "        q = query.strip().lower()\n",
    "        q = \" \".join(q.split())\n",
    "        scores = [0]*len(df_products)\n",
    "        if q in query_to_prod:\n",
    "            results = query_to_prod[q]\n",
    "            for i in results:\n",
    "                scores[product_id_to_node_id[i]] = 1 \n",
    "        else:\n",
    "            print(\"o\")\n",
    "        for l in range(len(scores)):\n",
    "            if scores[l] != 1:\n",
    "                scores[l] = random.uniform(0, 0.9)\n",
    "        print(scores)\n",
    "        raise EOFError\n",
    "        return scores\n",
    "\n",
    "x = Eval_db(test_dataloader, None)\n",
    "metrics = x.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1440114-1c3f-4483-a794-0b07ee04aa8d",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2248dba-081d-4fbd-bd19-ed66e429b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "tokenized_corpus = tokenized_corpus = [prod.split(\" \") for prod in all_product_info]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433c4473-0a2e-415f-86f9-8226f8e64e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.37033954224674864, 'nDCG': 0.4027936796923701, 'R-Precision': 0.1835023391199169, 'Precision@k': 0.16483106216165763, 'Scikit-MAP': 0.17278011363155316}\n"
     ]
    }
   ],
   "source": [
    "class Eval_bm25(Evaluator):\n",
    "    def forwards(self, query, p_embeddings):\n",
    "        scores = p_embeddings.get_scores(query)\n",
    "        return scores\n",
    "\n",
    "x = Eval_bm25(test_dataloader, bm25)\n",
    "metrics = x.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b04a6f-3ef0-47d2-9892-b42c0dbb8aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.37033954224674864, 'nDCG': 0.4027936796923701, 'R-Precision': 0.1835023391199169, 'Precision@k': 0.16483106216165763, 'Scikit-MAP': 0.17278011363155316}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)\n",
    "with open(f'outputs/bm25-{amazon}.txt', 'a') as f:\n",
    "    f.write(f'bm25-{test_subset,training_version} :: {str(metrics)} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d489a4d1-07de-4b94-a0b1-1f4a4893998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query-Results for: I want to find hiking shoes for women\n",
      "['Timberland mens White Ledge Mid Waterproof Hiking Shoe, Wheat, 9.5 US', \"Crocs Unisex Men's and Women's Classic Clog, Khaki, 13 US\", 'Lined Refillable Vintage Writing Journal for Women, Retro Tree of Life Faux Leather Cover Notebook/Travel Diary,Wide Ruled Paper,Daily Use Gift for Bloggers/Teachers/Back to College Students (Brown)', \"Crocs Men's and Women's Classic Tie Dye Clog, Multi, 6 US\", 'Thinvik Bike Cleats for Look Keo Grip,Road Bike Look Keo Cleat with Anti-Slip Rubber Desgin.Bicycle Cleat Set for Indoor&Outdoor Cycling- 0 Float Degree', \"Timberland Women's Nellie Double Waterproof Ankle Boot,Navy,8 M US\", \"Timberland Women's Nellie Double Waterproof Ankle Boot,Navy,7.5 M US\", \"Timberland Women's Nellie Double Waterproof Ankle Boot,Black,7.5 M US Toddler\", 'AINIC Pleated Tennis Skirts for Women with Pockets Shorts High Waisted Golf Skorts Athletic Running Workout Sports Skirt White', 'Dirty Sexy Player (Dirty Games Book 1)']\n"
     ]
    }
   ],
   "source": [
    "## Manual Query\n",
    "def man_query(q, top_k = 10):\n",
    "    tokenized_query = q.split(\" \")\n",
    "    print(\"Query-Results for:\", q)\n",
    "    print(bm25.get_top_n(tokenized_query, df_products[product_txt], n=top_k))\n",
    "    \n",
    "man_query(\"I want to find hiking shoes for women\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f98167-94e8-4d15-b6bd-7ce4e59e6ecc",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5578d155-6a10-450d-b3ed-e5c84eed9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_embeddings = vectorizer.fit_transform(all_product_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da83a3b-04d7-4da8-8964-b0ab4299d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDataset(Dataset):\n",
    "    def __init__(self, df, batch_size=64):\n",
    "        self.pairs = []\n",
    "        query_ids = df['query_id'].tolist()         \n",
    "        queries = df['query'].tolist()\n",
    "        all_embeddings = vectorizer.transform(queries)\n",
    "        \n",
    "        for emb, qid in zip(all_embeddings, query_ids):\n",
    "            self.pairs.append((emb, qid))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb, qid = self.pairs[idx]\n",
    "        return emb, torch.tensor(qid)\n",
    "\n",
    "def collate_tfidf(batch):\n",
    "    emb = [item[0] for item in batch]\n",
    "    query_ids = torch.stack([item[1] for item in batch])\n",
    "    return emb, query_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e1a31f-c838-45c8-87ed-af307d7515c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QueryDataset(test_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11ccaac4-1de7-4198-a508-2b55995cccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval_tfidf(Evaluator):\n",
    "    def forwards(self, query, p_embeddings):\n",
    "        scores = cosine_similarity(query,p_embeddings)\n",
    "        return scores[0]\n",
    "\n",
    "x = Eval_tfidf(dataloader, tf_embeddings)\n",
    "metrics = x.evaluate(True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd11ca8f-5416-4b77-8466-02b611a3bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.5908344854120229, 'nDCG': 0.6165674369477443, 'R-Precision': 0.3506048489871642, 'Precision@k': 0.29512787007653535, 'Scikit-MAP': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)\n",
    "with open(f'outputs/tfidf-{amazon}.txt', 'a') as f:\n",
    "    f.write(f'tfidf-{test_subset,training_version} :: {str(metrics)} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d47d7297-8cf2-400e-856d-7c500ff8c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query-Results for: I want to find hiking shoes for men\n",
      "Product 1: WETIKE Girls Basketball Culture Shoes Air-Cushion Comfortable Basketball Shoes for Girls Breathable Kids Shoes Non-Slip Sneakers High Top Shoes for Boys Running Boys Tennis Shoes Size 4 Black\n",
      "Product 2: I Want To Be Free\n",
      "Product 3: Amazon Brand - find. Men's Boat Shoes,white (White White),US 9\n",
      "Product 4: Etistta 6 Pairs of Shoes + 2 Pairs of Socks Fits for 18 inch Doll Shoes American Dolls Accessories Get Panda or Unicorn Shoes and Boots or Skates\n",
      "Product 5: ALEADER hiitave Men/Womens Minimalist Barefoot Trail Running Shoes Wide Toe Glove Cross Trainers Hiking Shoes Black/Gray/Yellow US 11/11.5 Men\n",
      "Product 6: DREAM PAIRS Girls Tennis Running Shoes Athletic Sports Sneakers Baby Blue Size 1 Little Kid Contact-k\n",
      "Product 7: Timberland mens White Ledge Mid Waterproof Hiking Shoe, Wheat, 9.5 US\n",
      "Product 8: Nike Men's Revolution 5 Running Shoe, Midnight Navy/White-Dark Obsidian, 8 Regular US\n",
      "Product 9: Nike Men's Downshifter 9 Running Shoe, deep Royal Blue/White-Game Royal, 10 Regular US\n",
      "Product 10: adidas Women's Coast Star Shoes, ftwr White/Silver Met./ core Black, 6 M US\n"
     ]
    }
   ],
   "source": [
    "# MANUAL QUERY\n",
    "def man_query(q, top_k = 10):\n",
    "    print(\"Query-Results for:\", q)\n",
    "    veq_q = vectorizer.transform([q])\n",
    "    scores = cosine_similarity(veq_q, tf_embeddings)[0]\n",
    "    sim_indx = np.argsort(scores)[::-1].tolist()\n",
    "    for i in range(top_k):\n",
    "        prod_title = df_products[product_txt][sim_indx[i]]\n",
    "        print(f'Product {i+1}: {prod_title}')\n",
    "\n",
    "man_query('I want to find hiking shoes for men')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295b29e-24b7-454e-8b61-4c80e46d9706",
   "metadata": {},
   "source": [
    "## Sentence Transformer Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adf194c9-a8b7-4b09-ad8e-434c1869d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load in own sentence transformer Model\n",
    "sf_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "p_embeddings = sf_model.encode(all_product_info, batch_size=64, convert_to_tensor=True).to(torch.float32).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "919aa063-03ae-4402-aa77-cd2d769b4580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.6654926356376448, 'nDCG': 0.6807798725161996, 'R-Precision': 0.42868284380223604, 'Precision@k': 0.34888930371476573, 'Scikit-MAP': 0.47476294636017496}\n"
     ]
    }
   ],
   "source": [
    "class Eval_sf_undtrained(Evaluator):\n",
    "    def forwards(self, query, p_emb):\n",
    "        query= \" \".join(i for i in query)\n",
    "        q_emb = sf_model.encode(query)\n",
    "        sims = sf_model.similarity(q_emb, p_emb)\n",
    "        sim_score = sims.cpu().numpy()[0]        \n",
    "        return sim_score\n",
    "\n",
    "x = Eval_sf_undtrained(test_dataloader, p_embeddings)\n",
    "metrics = x.evaluate()\n",
    "print(metrics)\n",
    "with open(f'outputs/sbert-{amazon}.txt', 'a') as f:\n",
    "    f.write(f'sbert-{test_subset,training_version} :: {str(metrics)} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1b099ae-36a9-4cd0-b2c4-e446f41322e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query-Results for: zero drop womens hiking shoes\n",
      "Product 1: Joomra Women Barefoot Trail Running Shoes Size 6.5-7 Ladies Wide Minimalist Zero Drop Trekking Sneakers Gym Antislip Toes Hiking Cycling Footwear Red 37\n",
      "Product 2: Nike Womens Air Zoom Terra Kiger 6 Fashion Sneaker Womens Cj0220-400 Size 10\n",
      "Product 3: City Classified Women's Shoes Invest Suede Peep Toe Ankle Fashion Boots,Tan,8\n",
      "Product 4: CLARKS Originals Desert Boot Women's Suede Felt Chukka Shoe (9.5M) Grey\n",
      "Product 5: Nike Womens Air Vapormax 360 Womens Running Casual Shoes Ck2719-400 Size 5.5\n",
      "Product 6: Skechers womens Bright Sky fashion sneakers, White, 5.5 US\n",
      "Product 7: Liliana Women Fashionable Peep Open Toe Cutout Chunky Heel Bootie (11, MonclairBlack)\n",
      "Product 8: J. Adams Tracy Perforated Flat Bootie - Casual Open Toe Low Heel - Cut Out Shoe, Light Grey, 7.5\n",
      "Product 9: Skechers Sport Women's D'lites Resilient Slip-On Mule Sneaker, Black/White, 8 M US\n",
      "Product 10: ALTRA Women's AFW1953G Superior 4 Trail Running Shoes Sneakers, Black/Purple\n"
     ]
    }
   ],
   "source": [
    "# MANUAL QUERY\n",
    "def man_query(q, top_k = 10):\n",
    "    print(\"Query-Results for:\", q)\n",
    "    q_emb = sf_model.encode(q)\n",
    "    sims = sf_model.similarity(q_emb, p_embeddings)\n",
    "    scores = sims.cpu().numpy()[0]       \n",
    "    sim_indx = np.argsort(scores)[::-1].tolist()\n",
    "    for i in range(top_k):\n",
    "        prod_title = df_products[product_txt][sim_indx[i]]\n",
    "        print(f'Product {i+1}: {prod_title}')\n",
    "\n",
    "man_query('zero drop womens hiking shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf886a09-f43e-4820-b4e6-edafb47bfa31",
   "metadata": {},
   "source": [
    "## Sentence Transformer Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dac4721-7c5d-405b-8fdd-ce2669fe8eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_model_trained = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sf_model_trained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc2560a9-acdf-44b6-b8ee-4edc595d02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(dataset):\n",
    "    pairs = []\n",
    "    \n",
    "    # Extract all queries as a list \n",
    "    query_ids = dataset['query_id'].tolist()          # query, pos_name, neg_name\n",
    "    queries = dataset['query'].tolist()\n",
    "    pids = dataset['product_id'].tolist()\n",
    "    labels = dataset[label].tolist()\n",
    "\n",
    "    for emb, qid, pid, l in zip(queries, query_ids, pids, labels):\n",
    "        # Get all exact and rest pids\n",
    "        p_row = df_products[df_products['product_id'] == pid]\n",
    "        product_name = \" \".join([\n",
    "        str(i) for i in [\n",
    "            p_row[product_infos[0]].item(),\n",
    "            p_row[product_infos[1]].item(),\n",
    "            p_row[product_infos[2]].item()\n",
    "        ] if i and str(i).lower() != \"nan\"\n",
    "        ])\n",
    "        \n",
    "        pairs.append(InputExample(texts=[emb, product_name], label = label_map[l]))\n",
    "    return pairs\n",
    "\n",
    "def collaz(batch):\n",
    "    qid = [example[0] for example in batch]\n",
    "    q = [example[1] for example in batch]\n",
    "    return qid, q\n",
    "\n",
    "train_dataset = make_ds(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "#test_list = QueryDataset_sbert(test_data)\n",
    "#testdataloader =  DataLoader(test_list, batch_size=64, shuffle=True, collate_fn = collate_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2500601a-0aa6-459c-951e-ae1295954d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loss = losses.CoSENTLoss(model)\n",
    "#train_loss = losses.AnglELoss(model)\n",
    "train_loss = losses.CosineSimilarityLoss(sf_model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "622c72c6-6294-40f7-abeb-483dd3e2c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeebf8c3ed82449b9cd375ed89246c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='214' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [214/214 00:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sf_model_trained.fit(train_objectives=[(train_dataloader, train_loss)], epochs=2, warmup_steps=100)\n",
    "# save model changed epochs from 10 to 2\n",
    "#sf_model_trained.save(\"location_for_sentence_bert_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffdd7b18-4d3d-4929-928a-c8e4690ab644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR': 0.7250244520889169, 'nDCG': 0.7169340759640458, 'R-Precision': 0.47778256893916704, 'Precision@k': 0.39089042374463323, 'Scikit-MAP': 0.5277582821497365}\n"
     ]
    }
   ],
   "source": [
    "class Eval_sf_trained(Evaluator):\n",
    "    def forwards(self, query, p_emb):\n",
    "        query= \" \".join(i for i in query)\n",
    "        q_emb = sf_model_trained.encode(query)\n",
    "        sims = sf_model_trained.similarity(q_emb, p_emb)\n",
    "        sim_score = sims.cpu().numpy()[0]        \n",
    "        return sim_score\n",
    "\n",
    "\n",
    "p_embeddings = sf_model_trained.encode(all_product_info)\n",
    "\n",
    "x = Eval_sf_trained(test_dataloader, p_embeddings)\n",
    "metrics = x.evaluate()\n",
    "print(metrics)\n",
    "with open(f'outputs/sbert-trained-{amazon}.txt', 'a') as f:\n",
    "    f.write(f'sbert-trained-{test_subset,training_version} :: {str(metrics)} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "915f79aa-e524-4d89-a3c4-c6be68cc75cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query-Results for: zero drop womens hiking shoes\n",
      "Product 1: Joomra Women Barefoot Trail Running Shoes Size 6.5-7 Ladies Wide Minimalist Zero Drop Trekking Sneakers Gym Antislip Toes Hiking Cycling Footwear Red 37\n",
      "Product 2: Nike Womens Air Zoom Terra Kiger 6 Fashion Sneaker Womens Cj0220-400 Size 10\n",
      "Product 3: City Classified Women's Shoes Invest Suede Peep Toe Ankle Fashion Boots,Tan,8\n",
      "Product 4: Liliana Women Fashionable Peep Open Toe Cutout Chunky Heel Bootie (11, MonclairBlack)\n",
      "Product 5: Nike Womens Air Vapormax 360 Womens Running Casual Shoes Ck2719-400 Size 5.5\n",
      "Product 6: CLARKS Originals Desert Boot Women's Suede Felt Chukka Shoe (9.5M) Grey\n",
      "Product 7: Skechers Sport Women's D'Lites Memory Foam Lace-up Sneaker,White Silver,8 W US\n",
      "Product 8: Skechers womens Bright Sky fashion sneakers, White, 5.5 US\n",
      "Product 9: Skechers Sport Women's D'lites Resilient Slip-On Mule Sneaker, Black/White, 8 M US\n",
      "Product 10: Timberland Women's Mt Hayes Waterproof Chukka Boots (7 B(M) US, Navy/Brown)\n"
     ]
    }
   ],
   "source": [
    "# MANUAL QUERY\n",
    "def man_query(q, top_k = 10):\n",
    "    print(\"Query-Results for:\", q)\n",
    "    q_emb = sf_model_trained.encode(q)\n",
    "    sims = sf_model_trained.similarity(q_emb, p_embeddings)    \n",
    "    scores = sims.cpu().numpy()[0]       \n",
    "    sim_indx = np.argsort(scores)[::-1].tolist()\n",
    "    for i in range(top_k):\n",
    "        prod_title = df_products[product_txt][sim_indx[i]]\n",
    "        print(f'Product {i+1}: {prod_title}')\n",
    "\n",
    "man_query('zero drop womens hiking shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd78295-b92b-4d1a-8404-4f181721def5",
   "metadata": {},
   "source": [
    "## Cross Encoder with SBERT Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "229f5a5c-b401-4ba2-a86d-009ad7e2b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value\n",
    "cross_model_trained = CrossEncoder(\n",
    "    \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "    num_labels=1,\n",
    "    max_length=512,    # trim/pad all pairs to this length\n",
    "    device=device     # or \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fed4a0c5-cffe-4587-b309-c316d8d399b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_examples = []\n",
    "q, pn, l = [], [], []\n",
    "cross_train_data = train_data.copy()\n",
    "for _, row in cross_train_data.iterrows():\n",
    "    \n",
    "    query_text = f'Query: {row['query']}'\n",
    "    q.append(query_text)\n",
    "    \n",
    "    p_row = df_products[df_products['product_id'] == row['product_id']]\n",
    "    product_name = \" \".join([\n",
    "        str(i) for i in [\n",
    "            p_row[product_infos[0]].item(),\n",
    "            p_row[product_infos[1]].item(),\n",
    "            p_row[product_infos[2]].item()\n",
    "        ] if i and str(i).lower() != \"nan\"\n",
    "        ])\n",
    "\n",
    "    if 'product_color' in p_row.columns:\n",
    "        product_text = f\"Description: {product_name} Brand: {p_row['product_brand']} Color: {p_row['product_color']}\"\n",
    "    else:\n",
    "        product_text = f\"Description: {product_name} Category:{p_row['category hierarchy']} Class: {p_row['product_class']}\" \n",
    "    \n",
    "    pn.append(product_text)\n",
    "\n",
    "    l.append(float(label_map[row[label]]))\n",
    "\n",
    "# Just for correct type usage\n",
    "features = Features({'query':  Value('string'),'product': Value('string'),'label':  Value('float32'),})\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "      'query':   q,\n",
    "      'product': pn,\n",
    "      'label':   l\n",
    "    },\n",
    "    features=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfa27dc6-d3f3-4f0c-a15d-14861638a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_emb = sf_model_trained.encode(all_product_info)\n",
    "\n",
    "dev_samples = {}\n",
    "for _, row in test_data.iterrows():\n",
    "    query = row['query']\n",
    "    qid = row['query_id']\n",
    "\n",
    "    \n",
    "    q = f'Query:{query}'\n",
    "    dev_samples[qid] = {'query': q, 'positive': [], 'negative': []}\n",
    "\n",
    "    \n",
    "    q_emb = sf_model_trained.encode(query)\n",
    "    sims = sf_model_trained.similarity(q_emb, p_emb)\n",
    "    scores = sims.cpu().numpy()[0]        \n",
    "            \n",
    "    # Represents the node-indexes with decreasing similarity\n",
    "    sim_indx = np.argsort(scores)[::-1].tolist()\n",
    "    sim_indx = sim_indx[:100]\n",
    "\n",
    "    # For each of the products, add them to rel or irrel\n",
    "    for node_id in sim_indx:\n",
    "        #print(node_id)\n",
    "        pid = node_id_to_product_id.get(node_id)\n",
    "\n",
    "        p_row = df_products[df_products['product_id'] == pid]\n",
    "        #print(p_row)\n",
    "        product_name = \" \".join([\n",
    "        str(i) for i in [\n",
    "            p_row[product_infos[0]].item(),\n",
    "            p_row[product_infos[1]].item(),\n",
    "            p_row[product_infos[2]].item()\n",
    "        ] if i and str(i).lower() != \"nan\"\n",
    "        ])\n",
    "        if 'product_color' in p_row.columns:\n",
    "            product_text = f\"Description: {product_name} Brand: {p_row['product_brand']} Color: {p_row['product_color']}\"\n",
    "        else:\n",
    "            product_text = f\"Description: {product_name} Category:{p_row['category hierarchy']} Class:<{p_row['product_class']}\" \n",
    "        \n",
    "\n",
    "        if label_dict.get((qid,pid), 0) == 1:\n",
    "            dev_samples[qid]['positive'].append(product_text)\n",
    "        else:\n",
    "            dev_samples[qid]['negative'].append(product_text)\n",
    "            \n",
    "evaluator = CrossEncoderRerankingEvaluator(dev_samples, name='evaluate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a97afc4e-0c16-42e4-8ef7-0a80822f4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"model_save/croos_encoder\" \n",
    "args = CrossEncoderTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=MODEL_SAVE_PATH,\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c320bc6-4bc7-425a-a6dc-0d44d1b2739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2142' max='3210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2142/3210 02:26 < 01:12, 14.64 it/s, Epoch 10.00/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.821800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m trainer = CrossEncoderTrainer(\n\u001B[32m      2\u001B[39m     model=cross_model_trained,\n\u001B[32m      3\u001B[39m     args=args,\n\u001B[32m      4\u001B[39m     train_dataset=train_dataset,  \n\u001B[32m      5\u001B[39m     evaluator=evaluator,\n\u001B[32m      6\u001B[39m )\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTraining finished.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/transformers/trainer.py:2240\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2238\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2239\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2240\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2241\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2242\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2243\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2244\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2245\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/transformers/trainer.py:2555\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2548\u001B[39m context = (\n\u001B[32m   2549\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2550\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2551\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2552\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2553\u001B[39m )\n\u001B[32m   2554\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2555\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2557\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2558\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2559\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2560\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2561\u001B[39m ):\n\u001B[32m   2562\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2563\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/transformers/trainer.py:3791\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   3788\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   3789\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3791\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3793\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/accelerate/accelerator.py:2734\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2732\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2733\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2734\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/torch/_tensor.py:626\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    617\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    618\u001B[39m         Tensor.backward,\n\u001B[32m    619\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    624\u001B[39m         inputs=inputs,\n\u001B[32m    625\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jupyterenv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    822\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m823\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    824\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    827\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "trainer = CrossEncoderTrainer(\n",
    "    model=cross_model_trained,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,  \n",
    "    evaluator=evaluator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b06bf-adaa-406d-bd03-ee323cb2e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator(cross_model_trained)  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e2fc-206b-4286-9407-34ce27e687c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'cross + sbert.txt', 'a') as f:\n",
    "    f.write(f'cross+sbert-{test_subset,training_version, amazon} :: {str(result)} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55feb516-77c3-4ae3-9306-df11f4bfdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL QUERY\n",
    "def man_query(q, top_k = 10):\n",
    "    print(\"Query-Results for:\", q)\n",
    "    q_emb = sf_model_trained.encode(q)\n",
    "    sims = sf_model_trained.similarity(q_emb, p_embeddings)    \n",
    "    scores = sims.cpu().numpy()[0]       \n",
    "    sim_indx = np.argsort(scores)[::-1].tolist()[:100]\n",
    "    \n",
    "    for node_id in sim_indx:\n",
    "        #print(node_id)\n",
    "        pid = node_id_to_product_id.get(node_id)\n",
    "\n",
    "        p_row = df_products[df_products['product_id'] == pid]\n",
    "        #print(p_row)\n",
    "        product_name = \" \".join([\n",
    "        str(i) for i in [\n",
    "            p_row[product_infos[0]].item(),\n",
    "            p_row[product_infos[1]].item(),\n",
    "            p_row[product_infos[2]].item()\n",
    "        ] if i and str(i).lower() != \"nan\"\n",
    "        ])\n",
    "        if 'product_color' in p_row.columns:\n",
    "            product_text = f\"Description: {product_name} Brand: {p_row['product_brand']} Color: {p_row['product_color']}\"\n",
    "        else:\n",
    "            product_text = f\"Description: {product_name} Category:{p_row['category hierarchy']} Class:<{p_row['product_class']}\" \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    for i in range(top_k):\n",
    "        prod_title = df_products['product_title'][sim_indx[i]]\n",
    "        print(f'Product {i+1}: {prod_title}')\n",
    "\n",
    "man_query('zero drop womens hiking shoes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
